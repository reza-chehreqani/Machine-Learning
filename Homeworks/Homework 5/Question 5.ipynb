{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data in Machine Learning\n",
    "\n",
    "When working with datasets, it is common to encounter missing values. Handling these missing values is crucial because most machine learning algorithms, including Multilayer Perceptrons (MLPs), cannot directly process incomplete data. Below are four common methods for dealing with missing data, along with their advantages and disadvantages:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Removing Missing Data**\n",
    "   - **Description**: This method involves removing rows or columns that contain missing values.\n",
    "   - **Advantages**:\n",
    "     - Simple and easy to implement.\n",
    "     - Ensures that the dataset is complete and free of missing values.\n",
    "   - **Disadvantages**:\n",
    "     - Can lead to significant data loss, especially if missing values are widespread.\n",
    "     - May introduce bias if the missing data is not randomly distributed.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Imputation with Mean/Median/Mode**\n",
    "   - **Description**: Replace missing values with the mean (for numerical data), median (for skewed numerical data), or mode (for categorical data) of the column.\n",
    "   - **Advantages**:\n",
    "     - Preserves the size of the dataset.\n",
    "     - Easy to implement and computationally efficient.\n",
    "   - **Disadvantages**:\n",
    "     - Can reduce the variability in the data.\n",
    "     - May introduce bias if the missing data is not randomly distributed.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Forward or Backward Fill**\n",
    "   - **Description**: For time-series or ordered data, missing values can be filled using the previous (forward fill) or next (backward fill) value in the sequence.\n",
    "   - **Advantages**:\n",
    "     - Simple and effective for time-series data.\n",
    "     - Preserves the order and structure of the data.\n",
    "   - **Disadvantages**:\n",
    "     - Not suitable for non-sequential data.\n",
    "     - Can propagate errors if the filled values are incorrect.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Predictive Imputation**\n",
    "   - **Description**: Use machine learning models (e.g., regression, k-nearest neighbors) to predict and fill missing values based on other features in the dataset.\n",
    "   - **Advantages**:\n",
    "     - Can provide more accurate imputations by leveraging relationships between features.\n",
    "     - Preserves the structure and size of the dataset.\n",
    "   - **Disadvantages**:\n",
    "     - Computationally expensive.\n",
    "     - Requires careful tuning and validation to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1452</td>\n",
       "      <td>1453</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3675</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>762</td>\n",
       "      <td>763</td>\n",
       "      <td>60</td>\n",
       "      <td>FV</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>Con</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932</td>\n",
       "      <td>933</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11670</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435</td>\n",
       "      <td>436</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10667</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>ConLw</td>\n",
       "      <td>Normal</td>\n",
       "      <td>212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8176</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>323</td>\n",
       "      <td>324</td>\n",
       "      <td>20</td>\n",
       "      <td>RM</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5820</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>126175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>650</td>\n",
       "      <td>651</td>\n",
       "      <td>60</td>\n",
       "      <td>FV</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8125</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>205950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>439</td>\n",
       "      <td>440</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12354</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>800</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>ConLI</td>\n",
       "      <td>Normal</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>798</td>\n",
       "      <td>799</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13518</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>485000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    Id  MSSubClass MSZoning  LotFrontage  LotArea Street  \\\n",
       "0            135   136          20       RL         80.0    10400   Pave   \n",
       "1           1452  1453         180       RM         35.0     3675   Pave   \n",
       "2            762   763          60       FV         72.0     8640   Pave   \n",
       "3            932   933          20       RL         84.0    11670   Pave   \n",
       "4            435   436          60       RL         43.0    10667   Pave   \n",
       "...          ...   ...         ...      ...          ...      ...    ...   \n",
       "1455         331   332          20       RL         70.0     8176   Pave   \n",
       "1456         323   324          20       RM         49.0     5820   Pave   \n",
       "1457         650   651          60       FV         65.0     8125   Pave   \n",
       "1458         439   440          50       RL         67.0    12354   Pave   \n",
       "1459         798   799          60       RL        104.0    13518   Pave   \n",
       "\n",
       "     Alley LotShape LandContour  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0      NaN      Reg         Lvl  ...        0    NaN  MnPrv         NaN   \n",
       "1      NaN      Reg         Lvl  ...        0    NaN    NaN         NaN   \n",
       "2      NaN      Reg         Lvl  ...        0    NaN    NaN         NaN   \n",
       "3      NaN      IR1         Lvl  ...        0    NaN    NaN         NaN   \n",
       "4      NaN      IR2         Lvl  ...        0    NaN    NaN         NaN   \n",
       "...    ...      ...         ...  ...      ...    ...    ...         ...   \n",
       "1455   NaN      Reg         Lvl  ...        0    NaN    NaN         NaN   \n",
       "1456   NaN      Reg         Lvl  ...        0    NaN    NaN         NaN   \n",
       "1457   NaN      Reg         Lvl  ...        0    NaN    NaN         NaN   \n",
       "1458  Grvl      Reg         Lvl  ...        0    NaN  GdPrv        Shed   \n",
       "1459   NaN      Reg         Lvl  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold YrSold SaleType  SaleCondition  SalePrice  \n",
       "0          0      5   2008       WD         Normal     174000  \n",
       "1          0      5   2006       WD         Normal     145000  \n",
       "2          0      6   2010      Con         Normal     215200  \n",
       "3          0      3   2007       WD         Normal     320000  \n",
       "4          0      4   2009    ConLw         Normal     212000  \n",
       "...      ...    ...    ...      ...            ...        ...  \n",
       "1455       0      8   2007       WD         Normal     139000  \n",
       "1456       0      7   2006       WD         Normal     126175  \n",
       "1457       0      5   2008       WD         Normal     205950  \n",
       "1458     800      8   2009    ConLI         Normal     110000  \n",
       "1459       0      7   2009      New        Partial     485000  \n",
       "\n",
       "[1460 rows x 82 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data = pd.read_csv('House-Price-Prediction/train.csv')\n",
    "test_data = pd.read_csv('House-Price-Prediction/test.csv')\n",
    "\n",
    "# Combine the datasets to calculate missing values for all features\n",
    "combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values for each feature:\n",
      "PoolQC          99.520548\n",
      "MiscFeature     96.301370\n",
      "Alley           93.767123\n",
      "Fence           80.753425\n",
      "MasVnrType      59.726027\n",
      "FireplaceQu     47.260274\n",
      "LotFrontage     17.739726\n",
      "GarageType       5.547945\n",
      "GarageYrBlt      5.547945\n",
      "GarageFinish     5.547945\n",
      "GarageQual       5.547945\n",
      "GarageCond       5.547945\n",
      "BsmtFinType2     2.602740\n",
      "BsmtExposure     2.602740\n",
      "BsmtFinType1     2.534247\n",
      "BsmtCond         2.534247\n",
      "BsmtQual         2.534247\n",
      "MasVnrArea       0.547945\n",
      "Electrical       0.068493\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each feature\n",
    "missing_percentage = (combined_data.isnull().sum() / len(combined_data)) * 100\n",
    "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Percentage of missing values for each feature:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1452</td>\n",
       "      <td>1453</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3675</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>762</td>\n",
       "      <td>763</td>\n",
       "      <td>60</td>\n",
       "      <td>FV</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>Con</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932</td>\n",
       "      <td>933</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11670</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435</td>\n",
       "      <td>436</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10667</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>ConLw</td>\n",
       "      <td>Normal</td>\n",
       "      <td>212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>845</td>\n",
       "      <td>846</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>69.0</td>\n",
       "      <td>16647</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8176</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>323</td>\n",
       "      <td>324</td>\n",
       "      <td>20</td>\n",
       "      <td>RM</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5820</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>126175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>439</td>\n",
       "      <td>440</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12354</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>ConLI</td>\n",
       "      <td>Normal</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>798</td>\n",
       "      <td>799</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13518</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>485000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    Id  MSSubClass MSZoning  LotFrontage  LotArea Street  \\\n",
       "0            135   136          20       RL         80.0    10400   Pave   \n",
       "1           1452  1453         180       RM         35.0     3675   Pave   \n",
       "2            762   763          60       FV         72.0     8640   Pave   \n",
       "3            932   933          20       RL         84.0    11670   Pave   \n",
       "4            435   436          60       RL         43.0    10667   Pave   \n",
       "...          ...   ...         ...      ...          ...      ...    ...   \n",
       "1333         845   846          85       RL         69.0    16647   Pave   \n",
       "1334         331   332          20       RL         70.0     8176   Pave   \n",
       "1335         323   324          20       RM         49.0     5820   Pave   \n",
       "1336         439   440          50       RL         67.0    12354   Pave   \n",
       "1337         798   799          60       RL        104.0    13518   Pave   \n",
       "\n",
       "     LotShape LandContour Utilities  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0         Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1         Reg         Lvl    AllPub  ...             0         0           0   \n",
       "2         Reg         Lvl    AllPub  ...             0         0           0   \n",
       "3         IR1         Lvl    AllPub  ...             0         0           0   \n",
       "4         IR2         Lvl    AllPub  ...             0         0           0   \n",
       "...       ...         ...       ...  ...           ...       ...         ...   \n",
       "1333      IR1         Lvl    AllPub  ...             0         0           0   \n",
       "1334      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1335      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1336      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "1337      Reg         Lvl    AllPub  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0           0       0      5   2008        WD         Normal     174000  \n",
       "1           0       0      5   2006        WD         Normal     145000  \n",
       "2           0       0      6   2010       Con         Normal     215200  \n",
       "3           0       0      3   2007        WD         Normal     320000  \n",
       "4           0       0      4   2009     ConLw         Normal     212000  \n",
       "...       ...     ...    ...    ...       ...            ...        ...  \n",
       "1333        0       0      1   2007        WD         Normal     171000  \n",
       "1334        0       0      8   2007        WD         Normal     139000  \n",
       "1335        0       0      7   2006        WD         Normal     126175  \n",
       "1336        0     800      8   2009     ConLI         Normal     110000  \n",
       "1337        0       0      7   2009       New        Partial     485000  \n",
       "\n",
       "[1338 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Drop features with a high percentage of missing values (e.g., >50%)\n",
    "threshold_high = 50\n",
    "columns_to_drop_high = missing_percentage[missing_percentage > threshold_high].index\n",
    "combined_data = combined_data.drop(columns=columns_to_drop_high)\n",
    "\n",
    "# Step 2: Impute missing values for features with moderate missing percentages (e.g., 10%–50%)\n",
    "threshold_moderate = 10\n",
    "moderate_missing_features = missing_percentage[\n",
    "    (missing_percentage > threshold_moderate) & (missing_percentage <= threshold_high)\n",
    "].index\n",
    "\n",
    "# Impute numerical features with median\n",
    "numerical_features = combined_data[moderate_missing_features].select_dtypes(include=['int64', 'float64']).columns\n",
    "for feature in numerical_features:\n",
    "    combined_data[feature] = combined_data[feature].fillna(combined_data[feature].median())\n",
    "\n",
    "# Impute categorical features with mode\n",
    "categorical_features = combined_data[moderate_missing_features].select_dtypes(include=['object']).columns\n",
    "for feature in categorical_features:\n",
    "    combined_data[feature] = combined_data[feature].fillna(combined_data[feature].mode()[0])\n",
    "\n",
    "# Split the data back into training and test sets\n",
    "train_data = combined_data.iloc[:len(train_data)]\n",
    "test_data = combined_data.iloc[len(train_data):]\n",
    "\n",
    "# Step 3: Remove rows with a low percentage of missing values (e.g., <10%)\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the percentage of the most common value\n",
    "def most_common_value_percentage(column):\n",
    "    most_common_value = column.value_counts(normalize=True).max()\n",
    "    return most_common_value * 100\n",
    "\n",
    "# Calculate the percentage of the most common value for each feature\n",
    "low_variance_features = []\n",
    "threshold = 90\n",
    "\n",
    "for column in combined_data.columns:\n",
    "    percentage = most_common_value_percentage(train_data[column])\n",
    "    if percentage > threshold:\n",
    "        low_variance_features.append(column)\n",
    "\n",
    "# Drop the low-variance features from the dataset\n",
    "combined_data = combined_data.drop(columns=low_variance_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant features\n",
    "combined_data = combined_data.drop(columns='GarageYrBlt') # redundant with YearBuilt\n",
    "combined_data = combined_data.drop(columns='TotalBsmtSF') # redundant with BsmtFinSF1, BsmtFinSF2, and BsmtUnfSF\n",
    "combined_data = combined_data.drop(columns='GrLivArea') # redundant with 1stFlrSF and 2ndFlrSF\n",
    "combined_data = combined_data.drop(columns='Exterior2nd') # redundant with Exterior1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features\n",
    "numerical_features = combined_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Calculate Pearson correlation with SalePrice\n",
    "correlation_with_target = train_data[numerical_features].corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Set a correlation threshold\n",
    "threshold = 0.2\n",
    "\n",
    "# Identify features with low correlation\n",
    "low_correlation_features = correlation_with_target[correlation_with_target < threshold].index\n",
    "\n",
    "# Drop low-correlation features\n",
    "combined_data = combined_data.drop(columns=low_correlation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "train_data_encoded = combined_data.iloc[:len(train_data)].copy()\n",
    "\n",
    "for column in combined_data.select_dtypes(include=['object']).columns:\n",
    "    train_data_encoded[column] = label_encoder.fit_transform(train_data[column])\n",
    "\n",
    "# Calculate correlation for all features (including encoded categorical features)\n",
    "correlation_with_target = train_data_encoded.corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Set a correlation threshold\n",
    "threshold = 0.2\n",
    "\n",
    "# Identify features with low correlation\n",
    "low_correlation_features = correlation_with_target[correlation_with_target < threshold].index\n",
    "\n",
    "# Drop low-correlation features\n",
    "combined_data = combined_data.drop(columns=low_correlation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Select categorical features\n",
    "categorical_features = combined_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical features\n",
    "encoded_categorical_data = one_hot_encoder.fit_transform(combined_data[categorical_features])\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "encoded_categorical_df = pd.DataFrame(\n",
    "    encoded_categorical_data,\n",
    "    columns=one_hot_encoder.get_feature_names_out(categorical_features)\n",
    ")\n",
    "\n",
    "# Drop the original categorical columns and concatenate the encoded ones\n",
    "combined_data = combined_data.drop(columns=categorical_features)\n",
    "combined_data = pd.concat([combined_data, encoded_categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Split the data back into training and test sets\n",
    "train_data = combined_data.iloc[:len(train_data)]\n",
    "test_data = combined_data.iloc[len(train_data):]\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_data_scaled = min_max_scaler.fit_transform(train_data)\n",
    "test_data_scaled = min_max_scaler.transform(test_data)\n",
    "\n",
    "label_index = combined_data.columns.get_loc('SalePrice')\n",
    "\n",
    "# Split the data into features and target\n",
    "X_train = np.delete(train_data_scaled, label_index, axis=1)\n",
    "X_test = np.delete(test_data_scaled, label_index, axis=1)\n",
    "y_train = train_data_scaled[:, label_index]\n",
    "y_test = test_data_scaled[:, label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch 200, Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch 300, Loss: 0.0051, Val Loss: 0.0057\n",
      "Epoch 400, Loss: 0.0048, Val Loss: 0.0054\n",
      "Epoch 500, Loss: 0.0045, Val Loss: 0.0052\n",
      "Epoch 600, Loss: 0.0043, Val Loss: 0.0050\n",
      "Epoch 700, Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch 800, Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch 900, Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch 1000, Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch 1100, Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch 1200, Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch 1300, Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch 1400, Loss: 0.0030, Val Loss: 0.0044\n",
      "Epoch 1500, Loss: 0.0029, Val Loss: 0.0044\n",
      "Epoch 1600, Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch 1700, Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch 1800, Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch 1900, Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch 2000, Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch 2100, Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch 2200, Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch 2300, Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch 2400, Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch 2500, Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch 2600, Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch 2700, Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch 2800, Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch 2900, Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch 3000, Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch 3100, Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch 3200, Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch 3300, Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch 3400, Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch 3500, Loss: 0.0020, Val Loss: 0.0039\n",
      "Epoch 3600, Loss: 0.0020, Val Loss: 0.0039\n",
      "Epoch 3700, Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch 3800, Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch 3900, Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch 4000, Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch 4100, Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch 4200, Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch 4300, Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch 4400, Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch 4500, Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch 4600, Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch 4700, Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch 4800, Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch 4900, Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch 5000, Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch 5100, Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch 5200, Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch 5300, Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch 5400, Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch 5500, Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch 5600, Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch 5700, Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch 5800, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 5900, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6000, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6100, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6200, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6300, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6400, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6500, Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch 6600, Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch 6700, Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch 6800, Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch 6900, Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch 7000, Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch 7100, Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch 7200, Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch 7300, Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch 7400, Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch 7500, Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch 7600, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 7700, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 7800, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 7900, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 8000, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 8100, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 8200, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 8300, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 8400, Loss: 0.0014, Val Loss: 0.0035\n",
      "Epoch 8500, Loss: 0.0013, Val Loss: 0.0035\n",
      "Epoch 8600, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 8700, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 8800, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 8900, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9000, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9100, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9200, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9300, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9400, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9500, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9600, Loss: 0.0013, Val Loss: 0.0034\n",
      "Epoch 9700, Loss: 0.0012, Val Loss: 0.0034\n",
      "Epoch 9800, Loss: 0.0012, Val Loss: 0.0034\n",
      "Epoch 9900, Loss: 0.0012, Val Loss: 0.0034\n",
      "Epoch 10000, Loss: 0.0012, Val Loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layers, learning_rate, batch_size=2):\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(len(layers) - 1):\n",
    "            self.weights.append(np.random.randn(layers[i], layers[i+1]))\n",
    "            self.biases.append(np.zeros((1, layers[i+1])))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        activations = [X]\n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            X = self.relu(np.dot(X, W) + b)\n",
    "            activations.append(X)\n",
    "        return activations\n",
    "    \n",
    "    def backward(self, activations, y):\n",
    "        deltas = [activations[-1] - y]\n",
    "        \n",
    "        for i in range(len(self.weights) - 1, 0, -1):\n",
    "            deltas.append(deltas[-1].dot(self.weights[i].T) * self.relu_derivative(activations[i]))\n",
    "        deltas.reverse()\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * activations[i].T.dot(deltas[i])\n",
    "            self.biases[i] -= self.learning_rate * np.sum(deltas[i], axis=0, keepdims=True)\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs):\n",
    "        y_train_reshaped = y_train.reshape(-1, 1)\n",
    "\n",
    "        history = {\"loss\": [], \"val_loss\": []}\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(X_train), self.batch_size):\n",
    "                activations = self.forward(X_train[i:i + self.batch_size])\n",
    "                self.backward(activations, y_train_reshaped[i:i + self.batch_size])\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                y_train_pred, y_val_pred = self.predict(X_train), self.predict(X_val)\n",
    "                loss, val_loss = np.mean((y_train - y_train_pred) ** 2), np.mean((y_val - y_val_pred) ** 2)\n",
    "                print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "                history[\"loss\"].append(loss)\n",
    "                history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        return history\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)[-1].reshape(-1)\n",
    "\n",
    "# Define and train the MLP\n",
    "num_features = X_train.shape[1]\n",
    "mlp = MLP(layers=[num_features, 32, 1], learning_rate=0.01)\n",
    "history = mlp.train(X_train, y_train, X_test, y_test, epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def log_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.log1p(y_true) - np.log1p(y_pred)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set metrics:\n",
      "RMSE: 0.0349\n",
      "MAE: 0.0262\n",
      "MAPE: 21.0607\n",
      "Log RMSE: 0.0284\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the train set\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "\n",
    "print(\"Train set metrics:\")\n",
    "print(f\"RMSE: {rmse(y_train, y_train_pred):.4f}\")\n",
    "print(f\"MAE: {mae(y_train, y_train_pred):.4f}\")\n",
    "print(f\"MAPE: {mape(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Log RMSE: {log_rmse(y_train, y_train_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set metrics:\n",
      "RMSE: 0.0581\n",
      "MAE: 0.0402\n",
      "MAPE: 38.4258\n",
      "Log RMSE: 0.0455\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Test set metrics:\")\n",
    "print(f\"RMSE: {rmse(y_test, y_test_pred):.4f}\")\n",
    "print(f\"MAE: {mae(y_test, y_test_pred):.4f}\")\n",
    "print(f\"MAPE: {mape(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Log RMSE: {log_rmse(y_test, y_test_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
